# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14IV1x3aC3PmV9utBBtUYtQnpq-dpkoE7
"""

from google.colab import drive
drive.mount('/drive')

!mkdir template

!mkdir static

pip install flask-ngrok

!pip install pyngrok
!ngrok authtoken 2G29BS33JSBZ65un0XrEO5M2Y8w_7RVZYec1CaP1NV8KS6S6k

pip install downcast

import pandas as pd
import pickle
from tqdm import tqdm
import numpy as np
from downcast import reduce
import warnings
warnings.filterwarnings("ignore")
from sklearn.preprocessing import LabelEncoder
from flask import Flask,request,jsonify,render_template,abort,make_response 
from flask_ngrok import run_with_ngrok


app = Flask(__name__, template_folder='template')
run_with_ngrok(app)

#Loading datasets
calendar = pd.read_csv('/drive/My Drive/calendar.csv')
calendar = calendar.fillna('no_event')
calendar = reduce(calendar)
sales_train_eval = pd.read_csv('/drive/My Drive/sales_train_evaluation.csv')
sales_train_eval = reduce(sales_train_eval)
sell_price = pd.read_csv('/drive/My Drive/sell_prices.csv')
sell_price = reduce(sell_price)

items=sales_train_eval['item_id'].unique().tolist()
stores=sales_train_eval['store_id'].unique().tolist()

def func(x):

    df = pd.melt(x,id_vars=['id','item_id','dept_id','cat_id','store_id','state_id'],var_name='d',value_name='sales')
    df = pd.merge(df,calendar,on='d',how='left')
    df = pd.merge(df,sell_price,on=['item_id','store_id','wm_yr_wk'],how='left')

    #Median imputation of price column
    df['sell_price']=df['sell_price'].fillna(df.groupby('id')['sell_price'].transform('mean'))

    #Extract number from string
    df['d'] = df['d'].str.extract(r"(\d+)").astype(np.int16)

    #deleting the rows which has data before 1st Oct 2014
    df = df[(df['date'] >= '2014-10-01')]

    df = reduce(df)

    #Removing weekday column and adding is_weekend feature
    df["is_Weekend"]=df['wday'].map(lambda x: 1 if x in [1,2] else 0)
    df=df.drop("weekday",axis=1)

    # Converting snap_CA,snap_WI,snap_TX into one feature named snap
    df.loc[df['state_id'] == 'CA', 'snap'] = df.loc[df['state_id'] == 'CA']['snap_CA']
    df.loc[df['state_id'] == 'TX', 'snap'] = df.loc[df['state_id'] == 'TX']['snap_TX']
    df.loc[df['state_id'] == 'WI', 'snap'] = df.loc[df['state_id'] == 'WI']['snap_WI']
    df.drop(['snap_CA','snap_TX','snap_WI'],axis=1,inplace=True)

    #adding day of month column
    df['day_of_month'] =  df['date'].dt.strftime("%d")
    df['day_of_month'] = df['day_of_month'].astype('int')

    #label encoding categorical features
    column = ['id','item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']
    for feature in column:
        encoder = LabelEncoder()
        df[feature] = encoder.fit_transform(df[feature])
    
    #Adding lag features
    lags = [1,7,28,30]
    for lag in tqdm(lags):
        df['lag_'+str(lag)] = df.groupby(['id'],as_index=False)['sales'].shift(lag).astype(np.float16)

    #Adding rolling window features
    window = [7,14,28,35,42]
    for i in tqdm(window):
        func = lambda x: x.rolling(i).median()
        df['rolling_median_'+str(i)] = df.groupby(['id'],as_index=False)['sales'].transform(func)

    df['rolling_sales_mean'] = df.groupby(['item_id','dept_id','cat_id','store_id','state_id'])['sales'].transform(lambda x: x.rolling(window=7).mean()).astype(np.float16)

    #deleting the rows which has data before 1st Jan 2015
    df = df[(df['date'] >= '2015-01-01')]

    #dropping wm_yr_wk column
    df.drop('wm_yr_wk',axis=1,inplace=True)
    #dropping date column
    df = df.drop('date',axis=1)
    df = df.reset_index(drop=True)
    df=df.drop(['sales'],axis=1)
    
    days=[]
    for i in range(1914,1942):
        days.append(i)
    X_test=df.loc[df['d'].isin(days)]
    #Loading trained LGB model 
    with open('trained_model.pkl','rb') as f:
        model=pickle.load(f)
    pred=pd.DataFrame()
    pred['id']=x['id'] 
    j=1
    k=1
    for i in range(1914,1942):
        pred['F'+str(k)]=model.predict(X_test[X_test['d']==(i)]) 
        k+=1    
    return np.round(pred)

@app.route('/')
def index():
    return render_template('index.html')    

@app.route('/predict',methods=["GET","POST"])
def predict():
    if request.method == "POST":
        # getting input with name = product in HTML form
        p=request.form.get("item")
        # getting input with name = store in HTML form 
        s=request.form.get("store") 
        #Checking if item_id and store_id entered by user is valid
        if (p in items) and (s in stores):
            df_temp = sales_train_eval.loc[sales_train_eval['item_id']==p]
            df_temp = df_temp.loc[df_temp['store_id']==s]
            pred_values=func(df_temp)
            pred_values=pred_values.values.reshape(-1).tolist()[1:]
            x = pd.date_range(start='2016/04/25',end='2016/05/22')
            x = x.strftime('%Y-%m-%d')
            z=zip(x,pred_values)
        
        else:
            #Raise error if invalid ITEM_ID or STORE_ID
            response=make_response(jsonify(message="ITEM ID or STORE ID is Invalid. Please Enter Valid Details "),406)
            abort(response)

        return render_template('predict.html',x=z,store=s,item=p) 
            

if __name__ == "__main__":
    app.run()