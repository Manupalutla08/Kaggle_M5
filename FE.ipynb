{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: downcast in /home/manaswini_palutla8/.local/lib/python3.8/site-packages (0.0.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install downcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "from downcast import reduce\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gc\n",
    "import pickle\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = pd.read_csv('calendar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with Null values in calendar dataset  ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n"
     ]
    }
   ],
   "source": [
    "#deleting the rows which has data after 22nd May 2016 i.e, days after 1941 \n",
    "calendar = calendar[(calendar['date'] <= '2016-05-22')]\n",
    "#Checking for NULL or Nan values\n",
    "print(\"Columns with Null values in calendar dataset \",calendar.columns[calendar.isna().any()].tolist())\n",
    "#Replacing Nan values with 'no_event' - value\n",
    "calendar=calendar.fillna('no_event')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading sales_train_eval dataset\n",
    "sales_train_eval = pd.read_csv('sales_train_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading sell_prices dataset\n",
    "sell_price = pd.read_csv('sell_prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downcasting the dataframes to reduce the amount of storage used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory usage of calendar dataframe reduced by 25.33067651400899 percent\n",
      "memory usage of sales dataframe reduced by 21.31192592896515 percent\n",
      "memory usage of price dataframe reduced by 4.797418193536785 percent\n"
     ]
    }
   ],
   "source": [
    "cal_bfr = calendar.memory_usage(deep=True).sum()\n",
    "calendar=reduce(calendar)\n",
    "cal_aftr = calendar.memory_usage(deep=True).sum()\n",
    "sales_bfr = sales_train_eval.memory_usage(deep=True).sum()\n",
    "sales_train_eval=reduce(sales_train_eval)\n",
    "sales_aftr = sales_train_eval.memory_usage(deep=True).sum()\n",
    "price_bfr = sell_price.memory_usage(deep=True).sum()\n",
    "sell_price=reduce(sell_price)\n",
    "price_aftr = sell_price.memory_usage(deep=True).sum()\n",
    "\n",
    "print(\"memory usage of calendar dataframe reduced by\",cal_aftr/cal_bfr * 100,\"percent\")\n",
    "print(\"memory usage of sales dataframe reduced by\",sales_aftr/sales_bfr * 100,\"percent\")\n",
    "print(\"memory usage of price dataframe reduced by\",price_aftr/price_bfr * 100,\"percent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe is pivoted to have all the sales data under a single column\n",
    "sales_final=sales_train_eval.melt(id_vars=['id', 'item_id', 'dept_id', 'cat_id', \n",
    "                                           'store_id', 'state_id'], var_name='d',value_name='sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging sales data with calendar data to plot total sales per day(in terms of date)\n",
    "sales_final=sales_final.merge(calendar,on='d',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for columns with Nan values \n",
    "sales_final.columns[sales_final.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merging with price dataframe\n",
    "sales_final=sales_final.merge(sell_price,on=['wm_yr_wk','item_id','store_id'],how='left')\n",
    "sales_final.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sell_price']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for columns with Nan values \n",
    "sales_final.columns[sales_final.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no NULL values before merge with sell_prices dataframe.But after merge we can see NULL values\n",
    "in 'sell_price' column. This means the particular item is not in stock in that particular store on a \n",
    "given day.We will handle NULL values with imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Median imputation\n",
    "sales_final['sell_price'].fillna(sales_final.groupby(['item_id','store_id'])['sell_price'].transform('median'),\n",
    "                              inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to memory constraints I will be using data from 1st Jan 2014 to train the model. When lag features are added, it is resulting in Nan values in first few rows. \n",
    "To avoid computational errors due to Nan values, I will be considering data from 1st October 2014. After lag features are added, I will use the data from 1st Jan 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting the rows which has data before 1st Oct 2014\n",
    "sales_final = sales_final[(sales_final['date'] >= '2014-10-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#deleting unused dataframes to freeup memory space\n",
    "del calendar\n",
    "del sales_train_eval\n",
    "del sell_price\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract number from string\n",
    "sales_final['d'] = sales_final['d'].str.extract(r\"(\\d+)\").astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_final = sales_final.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>...</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1342</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>11435</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>no_event</td>\n",
       "      <td>no_event</td>\n",
       "      <td>no_event</td>\n",
       "      <td>no_event</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.257812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1342</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>11435</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>no_event</td>\n",
       "      <td>no_event</td>\n",
       "      <td>no_event</td>\n",
       "      <td>no_event</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1342</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>11435</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>no_event</td>\n",
       "      <td>no_event</td>\n",
       "      <td>no_event</td>\n",
       "      <td>no_event</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1342</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>11435</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>no_event</td>\n",
       "      <td>no_event</td>\n",
       "      <td>no_event</td>\n",
       "      <td>no_event</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.640625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1342</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>11435</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>no_event</td>\n",
       "      <td>no_event</td>\n",
       "      <td>no_event</td>\n",
       "      <td>no_event</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.880859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        item_id    dept_id   cat_id store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_evaluation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1   \n",
       "1  HOBBIES_1_002_CA_1_evaluation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1   \n",
       "2  HOBBIES_1_003_CA_1_evaluation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1   \n",
       "3  HOBBIES_1_004_CA_1_evaluation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1   \n",
       "4  HOBBIES_1_005_CA_1_evaluation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1   \n",
       "\n",
       "  state_id     d  sales       date  wm_yr_wk  ... month  year  event_name_1  \\\n",
       "0       CA  1342      2 2014-10-01     11435  ...    10  2014      no_event   \n",
       "1       CA  1342      0 2014-10-01     11435  ...    10  2014      no_event   \n",
       "2       CA  1342      0 2014-10-01     11435  ...    10  2014      no_event   \n",
       "3       CA  1342      0 2014-10-01     11435  ...    10  2014      no_event   \n",
       "4       CA  1342      0 2014-10-01     11435  ...    10  2014      no_event   \n",
       "\n",
       "   event_type_1 event_name_2 event_type_2 snap_CA snap_TX  snap_WI  sell_price  \n",
       "0      no_event     no_event     no_event       1       1        0    8.257812  \n",
       "1      no_event     no_event     no_event       1       1        0    3.970703  \n",
       "2      no_event     no_event     no_event       1       1        0    2.970703  \n",
       "3      no_event     no_event     no_event       1       1        0    4.640625  \n",
       "4      no_event     no_event     no_event       1       1        0    2.880859  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering on calendar dataframe columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing weekday column and adding is_weekend feature\n",
    "\n",
    "sales_final[\"is_Weekend\"]=sales_final['wday'].map(lambda x: 1 if x in [1,2] else 0)\n",
    "sales_final=sales_final.drop(\"weekday\",axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting snap_CA,snap_WI,snap_TX into one feature named snap\n",
    "\n",
    "sales_final.loc[sales_final['state_id'] == 'CA', 'snap'] = sales_final.loc[sales_final['state_id'] == 'CA']['snap_CA']\n",
    "sales_final.loc[sales_final['state_id'] == 'TX', 'snap'] = sales_final.loc[sales_final['state_id'] == 'TX']['snap_TX']\n",
    "sales_final.loc[sales_final['state_id'] == 'WI', 'snap'] = sales_final.loc[sales_final['state_id'] == 'WI']['snap_WI']\n",
    "sales_final.drop(['snap_CA','snap_TX','snap_WI'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding day of month column\n",
    "sales_final['day_of_month'] =  sales_final['date'].dt.strftime(\"%d\")\n",
    "sales_final['day_of_month'] = sales_final['day_of_month'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label encoding categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['id','item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "for feature in column:\n",
    "    encoder = LabelEncoder()\n",
    "    sales_final[feature] = encoder.fit_transform(sales_final[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time series related feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:10<00:00,  2.58s/it]\n"
     ]
    }
   ],
   "source": [
    "#Adding lag features\n",
    "lags = [1,7,28,30]\n",
    "for lag in tqdm(lags):\n",
    "    sales_final['lag_'+str(lag)] = sales_final.groupby(['id'],as_index=False)['sales'].shift(lag).astype(np.float16)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:14<00:00, 26.90s/it]\n"
     ]
    }
   ],
   "source": [
    "#Adding rolling window features\n",
    "window = [7,14,28,35,42]\n",
    "for i in tqdm(window):\n",
    "    func = lambda x: x.rolling(i).median()\n",
    "    sales_final['rolling_median_'+str(i)] = sales_final.groupby(['id'],as_index=False)['sales'].transform(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_final['rolling_sales_mean'] = sales_final.groupby(['item_id','dept_id',\n",
    "               'cat_id','store_id','state_id'])['sales'].transform(lambda x: x.rolling(window=7).mean()).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting the rows which has data before 1st Jan 2015\n",
    "sales_final = sales_final[(sales_final['date'] >= '2015-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for columns with Nan values \n",
    "sales_final.columns[sales_final.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping wm_yr_wk column\n",
    "sales_final.drop('wm_yr_wk',axis=1,inplace=True)\n",
    "#dropping date column\n",
    "sales_final = sales_final.drop('date',axis=1)\n",
    "sales_final = sales_final.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no NULL values in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_final = reduce(sales_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the dataframe into train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a time series problem, dataset is split on temporal basis instead of random splitting using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set =  sales_final[(sales_final['d'] <= 1885)]\n",
    "valid_set = sales_final[(sales_final['d'] > 1885) & (sales_final['d'] <= 1913)]\n",
    "test_set = sales_final[(sales_final['d'] > 1913)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.to_pickle('X_train.pkl')\n",
    "valid_set.to_pickle('X_cv.pkl')\n",
    "test_set.to_pickle('X_test.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
